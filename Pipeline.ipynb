{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4454d153",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "This notebook is the pipeline that combines all of our work. You are able to supply the pipeline with a csv file of inputs and the pipeline will output a csv file that is the predictions for the supplied inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab5f7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b12a4",
   "metadata": {},
   "source": [
    "We don't include any pre-processing as this is all the test set. We only include feature engineering so that our model can output it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f22701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_arrays():\n",
    "\n",
    "    f = open(\"./funder_installer.csv\", \"r\")\n",
    "    lines = f.readlines()\n",
    "    values = lines[1:]\n",
    "    header = lines[0].strip('\\n').split(\",\")\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for i in range(len(values)):\n",
    "\n",
    "        data[header[i]] = values[i].strip('\\n').split(\",\")\n",
    "\n",
    "    gov = data['GOV']\n",
    "    charity = data['CHARITY']\n",
    "    local_gov = data['LOCAL_GOV']\n",
    "    private = data['PRIVATE']\n",
    "    foreign = data['FOREIGN']\n",
    "    school = data['SCHOOL']\n",
    "    religious = data['RELIGIOUS']\n",
    "    \n",
    "    return (gov, local_gov, private, religious, charity, school, foreign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea464ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_inst_fund(x, f, data):\n",
    "    gov, local_gov, private, religious, charity, school, foreign = data\n",
    "    try:\n",
    "        x = f(x)\n",
    "        if x in gov:\n",
    "            return 'Government'\n",
    "        elif x in local_gov:\n",
    "            return 'Local Government'\n",
    "        elif x in private:\n",
    "            return 'Private'\n",
    "        elif x in religious:\n",
    "            return 'Religious'\n",
    "        elif x in charity:\n",
    "            return 'Charity'\n",
    "        elif x in school:\n",
    "            return 'School'\n",
    "        elif x in foreign:\n",
    "            return 'Foreign Aid'\n",
    "        \n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    except AttributeError as e:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f300c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_construction_year (row):\n",
    "    if row['construction_year'] in range(1960,1970):\n",
    "        return \"60s\"\n",
    "    if row['construction_year'] in range(1970,1980):\n",
    "        return \"70s\"\n",
    "    if row['construction_year'] in range(1980,1990):\n",
    "        return \"80s\"\n",
    "    if row['construction_year'] in range(1990,2000):\n",
    "        return \"90s\"\n",
    "    if row['construction_year'] in range(2000,2010):\n",
    "        return \"2000s\"\n",
    "    if row['construction_year'] in range(2010, 2020):\n",
    "        return \"2010s\"\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55250123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_region (row):\n",
    "    if row['region'] in ['Arusha','Manyara','Kilimanjaro','Tanga']:\n",
    "        return \"Northern Zone\"\n",
    "    if row['region'] in ['Kagera','Mwanza','Shinyanga','Mara']:\n",
    "        return \"Lake Zone\"\n",
    "    if row['region'] in ['Lindi','Ruvuma','Mtwara']:\n",
    "        return \"Southern Zone\"\n",
    "    if row['region'] in ['Rukwa','Mbeya','Iringa']:\n",
    "        return \"Southern Highlands\"\n",
    "    if row['region'] in ['Morogoro','Pwani','Dar es Salaam']:\n",
    "        return \"Coastal Zone\"\n",
    "    if row['region'] in ['Kigoma']:\n",
    "        return \"Western Zone\"\n",
    "    if row['region'] in ['Tabora','Singida','Dodoma']:\n",
    "        return \"Central Zone\"\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c22cf53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author [Tom]\n",
    "\n",
    "def minmax_normalisation(df, col):\n",
    "    df[col + \"_minmaxnormalised\"] = ((df[col] - df[col].min()) / (df[col].max() / df[col].min()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57640253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \n",
    "    data = read_arrays()\n",
    "    f = lambda x: x.upper().replace(\" \", \"\").translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    df['cat_funder'] = df['funder'].apply(lambda x: cat_inst_fund(x, f, data))\n",
    "    df['cat_installer'] = df['installer'].apply(lambda x: cat_inst_fund(x, f, data))\n",
    "    df['construction_decade'] = df.apply(lambda row: label_construction_year(row), axis=1)\n",
    "    df['zones'] = df.apply(lambda row: label_region(row), axis=1)\n",
    "    df = minmax_normalisation(df, \"gps_height\")\n",
    "    df['permit'] = df['permit'].astype(str)\n",
    "    df['public_meeting'] = df['public_meeting'].astype(str)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31eecdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b11292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(df):\n",
    "    df['recorded_year'] = pd.DatetimeIndex(df ['date_recorded']).year\n",
    "    df['age'] = df['recorded_year'] - df['construction_year']\n",
    "    df['age'] = df['age'].apply(lambda x: x if x < 100 else -1)\n",
    "    df = df.drop('recorded_year',axis=1)\n",
    "    \n",
    "    \n",
    "    df['month'] = pd.DatetimeIndex(df['date_recorded']).month\n",
    "\n",
    "    # season encoder\n",
    "    # 1: 'short dry', 2: 'long rain', 3: 'long dry', 4: 'short rain'\n",
    "    season_mapper = {1: 1,2: 1, 3: 2, 4: 2, 5: 2, 6: 3, 7: 3,\n",
    "                     8: 3, 9: 3, 10: 3, 11: 4, 12: 4}\n",
    "    #.p feature values to scale\n",
    "    df['season']=df['month'].replace(season_mapper)\n",
    "    df=df.drop('month', axis=1)\n",
    "    \n",
    "    df['consistent_water'] = np.where(df['quantity'] == 1, 1, 0)\n",
    "    df['source_below_sea_level'] = np.where(df['gps_height'] < df['amount_tsh'], 1, 0)\n",
    "    \n",
    "    # These features are almost definitely being dropped!\n",
    "    df.drop(columns = ['date_recorded', 'wpt_name','num_private','subvillage','region_code','district_code','lga','ward','recorded_by',\n",
    "                       'scheme_name','extraction_type','extraction_type_group','payment','quality_group','quantity_group',\n",
    "                       'source','waterpoint_type','construction_year','region','funder','installer'], inplace=True)\n",
    "    \n",
    "    # This list of features to use might change at some point.\n",
    "    df = df[['id', 'extraction_type_class', 'payment_type', 'quantity', 'source_type',\n",
    "               'waterpoint_type_group', 'cat_funder', 'construction_decade', 'consistent_water',\n",
    "               'age', 'season', 'water_quality', 'cat_installer', 'gps_height_minmaxnormalised',\n",
    "               'longitude', 'latitude', 'population']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06ef32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    \"\"\"\n",
    "    This function takes an input filename (dataframe), and outputs a dataframe\n",
    "    that can be processed by our model.\n",
    "    \n",
    "    TODO: Parameterize this -> we need to get the columns from a json file\n",
    "                            -> we need to get the new features from json? is this possible\n",
    "                            \n",
    "    Args:\n",
    "        filename (String): The .csv file to read\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame : the output pandas DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    fe_transformer = FunctionTransformer(feature_engineering)\n",
    "    mcl_encoder = MultiColumnLabelEncoder(columns = ['basin','public_meeting','scheme_management','permit','extraction_type_class',\n",
    "                                        'management','management_group','payment_type','water_quality','quantity',\n",
    "                                        'source_type','source_class','waterpoint_type_group',\n",
    "                                        'construction_decade','zones', 'cat_funder', 'cat_installer'])\n",
    "    fg_transformer = FunctionTransformer(feature_generation)\n",
    "    preprocessing_pipeline = Pipeline([('fe', fe_transformer), ('mcl', mcl_encoder), ('fg', fg_transformer)])\n",
    "    df = preprocessing_pipeline.fit_transform(df)\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1c8ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filename, model_file):\n",
    "    \n",
    "    df = preprocess(filename)\n",
    "    \n",
    "    \n",
    "    with open(model_file, 'rb') as f:\n",
    "        xgb_clf = pickle.load(f)\n",
    "        \n",
    "    id_col = df['id']\n",
    "    \n",
    "    df.drop('id', axis=1, inplace=True)\n",
    "    \n",
    "    preds = xgb_clf.predict(df)\n",
    "    \n",
    "    final_df = pd.DataFrame(preds, columns=['status_group'])\n",
    "    \n",
    "    final_df = pd.concat([id_col, final_df], axis=1)\n",
    "    \n",
    "    final_df = final_df.replace({'status_group' : { 0 : \"functional\", 1 : \"functional needs repair\", 2 : \"non functional\" } } )\n",
    "    \n",
    "    final_df.to_csv(\"test_results.csv\", index=False)\n",
    "    \n",
    "    return final_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d17d669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14845</th>\n",
       "      <td>39307</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14846</th>\n",
       "      <td>18990</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14847</th>\n",
       "      <td>28749</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14848</th>\n",
       "      <td>33492</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>68707</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14850 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    status_group\n",
       "0      50785  non functional\n",
       "1      51630      functional\n",
       "2      17168      functional\n",
       "3      45559  non functional\n",
       "4      49871      functional\n",
       "...      ...             ...\n",
       "14845  39307  non functional\n",
       "14846  18990      functional\n",
       "14847  28749      functional\n",
       "14848  33492      functional\n",
       "14849  68707  non functional\n",
       "\n",
       "[14850 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(\"./datasets/test_dataset.csv\", \"./models/XGB.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
