{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4454d153",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "This notebook is the pipeline that combines all of our work. You are able to supply the pipeline with a csv file of inputs and the pipeline will output a csv file that is the predictions for the supplied inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5f7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b12a4",
   "metadata": {},
   "source": [
    "We don't include any pre-processing as this is all the test set. We only include feature engineering so that our model can output it's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f22701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_arrays():\n",
    "\n",
    "    f = open(\"./funder_installer.csv\", \"r\")\n",
    "    lines = f.readlines()\n",
    "    values = lines[1:]\n",
    "    header = lines[0].strip('\\n').split(\",\")\n",
    "\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for i in range(len(values)):\n",
    "\n",
    "        data[header[i]] = values[i].strip('\\n').split(\",\")\n",
    "\n",
    "    gov = data['GOV']\n",
    "    charity = data['CHARITY']\n",
    "    local_gov = data['LOCAL_GOV']\n",
    "    private = data['PRIVATE']\n",
    "    foreign = data['FOREIGN']\n",
    "    school = data['SCHOOL']\n",
    "    religious = data['RELIGIOUS']\n",
    "    \n",
    "    return (gov, local_gov, private, religious, charity, school, foreign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea464ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_inst_fund(x, f, data):\n",
    "    gov, local_gov, private, religious, charity, school, foreign = data\n",
    "    try:\n",
    "        x = f(x)\n",
    "        if x in gov:\n",
    "            return 'Government'\n",
    "        elif x in local_gov:\n",
    "            return 'Local Government'\n",
    "        elif x in private:\n",
    "            return 'Private'\n",
    "        elif x in religious:\n",
    "            return 'Religious'\n",
    "        elif x in charity:\n",
    "            return 'Charity'\n",
    "        elif x in school:\n",
    "            return 'School'\n",
    "        elif x in foreign:\n",
    "            return 'Foreign Aid'\n",
    "        \n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    except AttributeError as e:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f300c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_construction_year (row):\n",
    "    if row['construction_year'] in range(1960,1970):\n",
    "        return \"60s\"\n",
    "    if row['construction_year'] in range(1970,1980):\n",
    "        return \"70s\"\n",
    "    if row['construction_year'] in range(1980,1990):\n",
    "        return \"80s\"\n",
    "    if row['construction_year'] in range(1990,2000):\n",
    "        return \"90s\"\n",
    "    if row['construction_year'] in range(2000,2010):\n",
    "        return \"2000s\"\n",
    "    if row['construction_year'] in range(2010, 2020):\n",
    "        return \"2010s\"\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55250123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_region (row):\n",
    "    if row['region'] in ['Arusha','Manyara','Kilimanjaro','Tanga']:\n",
    "        return \"Northern Zone\"\n",
    "    if row['region'] in ['Kagera','Mwanza','Shinyanga','Mara']:\n",
    "        return \"Lake Zone\"\n",
    "    if row['region'] in ['Lindi','Ruvuma','Mtwara']:\n",
    "        return \"Southern Zone\"\n",
    "    if row['region'] in ['Rukwa','Mbeya','Iringa']:\n",
    "        return \"Southern Highlands\"\n",
    "    if row['region'] in ['Morogoro','Pwani','Dar es Salaam']:\n",
    "        return \"Coastal Zone\"\n",
    "    if row['region'] in ['Kigoma']:\n",
    "        return \"Western Zone\"\n",
    "    if row['region'] in ['Tabora','Singida','Dodoma']:\n",
    "        return \"Central Zone\"\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22cf53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def minmax_normalisation(df, col):\n",
    "    df[col + \"_minmaxnormalised\"] = ((df[col] - df[col].min()) / (df[col].max() / df[col].min()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "131e867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zscore_normalisation(df, col):\n",
    "    df[col + \"_zscorenormalise\"] = ((df[col] - df[col].mean()) / df[col].std())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71f38d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlon_impute(df):\n",
    "\n",
    "    df['longitude_imputation'] = df['longitude']\n",
    "    df['latitude_imputation'] = df['latitude']\n",
    "\n",
    "    df['longitude_imputation'] = df['longitude_imputation'].replace(0, np.nan)\n",
    "    df['longitude_imputation'] = df['longitude_imputation'].fillna(df.groupby('region')['longitude_imputation'].transform('mean'))\n",
    "\n",
    "    df['latitude_imputation'] = df['latitude_imputation'].replace(-2.000000e-08, np.nan)\n",
    "    df['latitude_imputation'] = df['latitude_imputation'].fillna(df.groupby('region')['latitude_imputation'].transform('mean'))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57640253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \n",
    "    data = read_arrays()\n",
    "    f = lambda x: x.upper().replace(\" \", \"\").translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    df['cat_funder'] = df['funder'].apply(lambda x: cat_inst_fund(x, f, data))\n",
    "    df['cat_installer'] = df['installer'].apply(lambda x: cat_inst_fund(x, f, data))\n",
    "    df['construction_decade'] = df.apply(lambda row: label_construction_year(row), axis=1)\n",
    "    df['zones'] = df.apply(lambda row: label_region(row), axis=1)\n",
    "    df = minmax_normalisation(df, \"gps_height\")\n",
    "    df = zscore_normalisation(df, \"gps_height\")\n",
    "    df = latlon_impute(df)\n",
    "    df['permit'] = df['permit'].astype(str)\n",
    "    df['public_meeting'] = df['public_meeting'].astype(str)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31eecdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b11292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(df, voting_clf=True):\n",
    "    df['recorded_year'] = pd.DatetimeIndex(df ['date_recorded']).year\n",
    "    df['age'] = df['recorded_year'] - df['construction_year']\n",
    "    df['age'] = df['age'].apply(lambda x: x if x < 100 else -1)\n",
    "    df = df.drop('recorded_year',axis=1)\n",
    "    \n",
    "    \n",
    "    df['month'] = pd.DatetimeIndex(df['date_recorded']).month\n",
    "\n",
    "    # season encoder\n",
    "    # 1: 'short dry', 2: 'long rain', 3: 'long dry', 4: 'short rain'\n",
    "    season_mapper = {1: 1,2: 1, 3: 2, 4: 2, 5: 2, 6: 3, 7: 3,\n",
    "                     8: 3, 9: 3, 10: 3, 11: 4, 12: 4}\n",
    "    #.p feature values to scale\n",
    "    df['season']=df['month'].replace(season_mapper)\n",
    "    df=df.drop('month', axis=1)\n",
    "    \n",
    "    df['consistent_water'] = np.where(df['quantity'] == 1, 1, 0)\n",
    "    df['source_below_sea_level'] = np.where(df['gps_height'] < df['amount_tsh'], 1, 0)\n",
    "    \n",
    "    if voting_clf:\n",
    "        voting_features = ['age', 'latitude_imputation', 'longitude_imputation', 'construction_decade',\n",
    "                           'quality_group', 'basin', 'extraction_type', 'cat_installer', 'population',\n",
    "                           'gps_height_zscorenormalise', 'cat_funder', 'quantity', 'consistent_water',\n",
    "                           'source_class', 'zones', 'waterpoint_type', 'season', 'extraction_type_class',\n",
    "                           'payment']\n",
    "        return df[voting_features]\n",
    "    else:\n",
    "        # This list of features to use might change at some point.\n",
    "        df = df[['id', 'extraction_type_class', 'payment_type', 'quantity', 'source_type',\n",
    "                   'waterpoint_type_group', 'cat_funder', 'construction_decade', 'consistent_water',\n",
    "                   'age', 'season', 'water_quality', 'cat_installer', 'gps_height_minmaxnormalised',\n",
    "                   'longitude', 'latitude', 'population']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06ef32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    \"\"\"\n",
    "    This function takes an input filename (dataframe), and outputs a dataframe\n",
    "    that can be processed by our model.\n",
    "    \n",
    "    TODO: Parameterize this -> we need to get the columns from a json file\n",
    "                            -> we need to get the new features from json? is this possible\n",
    "                            \n",
    "    Args:\n",
    "        filename (String): The .csv file to read\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame : the output pandas DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    fe_transformer = FunctionTransformer(feature_engineering)\n",
    "    mcl_encoder = MultiColumnLabelEncoder(columns = ['basin','public_meeting','scheme_management','permit','extraction_type_class',\n",
    "                                                     'management','management_group','payment_type','water_quality','quantity',\n",
    "                                                     'source_type','source_class','waterpoint_type_group', 'construction_decade',\n",
    "                                                     'zones', 'cat_funder', 'cat_installer', 'extraction_type', 'payment',\n",
    "                                                     'waterpoint_type', 'extraction_type_group', 'quality_group','source'])\n",
    "    fg_transformer = FunctionTransformer(feature_generation)\n",
    "    preprocessing_pipeline = Pipeline([('fe', fe_transformer), ('mcl', mcl_encoder), ('fg', fg_transformer)])\n",
    "    df = preprocessing_pipeline.fit_transform(df)\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1c8ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filename, model_file, voting_clf=True):\n",
    "    \n",
    "    df = preprocess(filename)\n",
    "    \n",
    "    \n",
    "    with open(model_file, 'rb') as f:\n",
    "        clf = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    id_col = df['id']\n",
    "    \n",
    "    df.drop('id', axis=1, inplace=True)\n",
    "    \n",
    "    if voting_clf:\n",
    "        prob_preds = clf.predict_proba(df)\n",
    "        preds = np.argmax(prob_preds, axis=1)\n",
    "    else:\n",
    "        preds = clf.predict(df)\n",
    "    \n",
    "    final_df = pd.DataFrame(preds, columns=['status_group'])\n",
    "    \n",
    "    final_df = pd.concat([id_col, final_df], axis=1)\n",
    "    \n",
    "    final_df = final_df.replace({'status_group' : { 0 : \"functional\", 1 : \"functional needs repair\", 2 : \"non functional\" } } )\n",
    "    \n",
    "    final_df.to_csv(\"test_results.csv\", index=False)\n",
    "    \n",
    "    return final_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d17d669",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['population_original', 'funder_grouped', 'installer_grouped'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./datasets/test_dataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/voting.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(filename, model_file, voting_clf)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(filename, model_file, voting_clf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(model_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m         clf \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     22\u001b[0m fg_transformer \u001b[38;5;241m=\u001b[39m FunctionTransformer(feature_generation)\n\u001b[1;32m     23\u001b[0m preprocessing_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfe\u001b[39m\u001b[38;5;124m'\u001b[39m, fe_transformer), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcl\u001b[39m\u001b[38;5;124m'\u001b[39m, mcl_encoder), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfg\u001b[39m\u001b[38;5;124m'\u001b[39m, fg_transformer)])\n\u001b[0;32m---> 24\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:445\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    443\u001b[0m fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\u001b[38;5;241m.\u001b[39mtransform(Xt)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_function_transformer.py:238\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    Transformed input.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_function_transformer.py:310\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     func \u001b[38;5;241m=\u001b[39m _identity\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mfeature_generation\u001b[0;34m(df, voting_clf)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m voting_clf:\n\u001b[1;32m     22\u001b[0m     voting_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude_imputation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude_imputation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantity\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextraction_type_class\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgps_height\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwaterpoint_type_group\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopulation_original\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayment_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunder_grouped\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstaller_grouped\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanagement\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwater_quality\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublic_meeting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvoting_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# This list of features to use might change at some point.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextraction_type_class\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayment_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwaterpoint_type_group\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_funder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstruction_decade\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconsistent_water\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     30\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwater_quality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_installer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgps_height_minmaxnormalised\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopulation\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3464\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3463\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3464\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3466\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1314\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 1314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_read_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(ax\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1317\u001b[0m     ax, (IntervalIndex, CategoricalIndex)\n\u001b[1;32m   1318\u001b[0m ):\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# For CategoricalIndex take instead of reindex to preserve dtype.\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;66;03m#  For IntervalIndex this is to map integers to the Intervals they match to.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1377\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1376\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 1377\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['population_original', 'funder_grouped', 'installer_grouped'] not in index\""
     ]
    }
   ],
   "source": [
    "main(\"./datasets/test_dataset.csv\", \"./models/voting.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
